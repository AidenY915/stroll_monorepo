import re
from selenium import webdriver
from selenium.webdriver.chrome.options import Options
from selenium.webdriver.common.by import By
from selenium.webdriver.chrome.service import Service
from selenium.common.exceptions import NoSuchElementException
import time
import json
from urllib.parse import quote
import requests
import hashlib

from dotenv import load_dotenv
import os


CHROMEDRIVER_PATH = None
CHROME_PATH = None
driver = None
DIRECTORY_PATH = __file__[0:__file__.rfind(os.sep)]
TMP_PATH = None

def init():
    """Chrome ë“œë¼ì´ë²„ë¥¼ ì´ˆê¸°í™”í•˜ê³  í•„ìš”í•œ ì„¤ì •ì„ ë¡œë“œí•©ë‹ˆë‹¤."""
    global driver
    global DIRECTORY_PATH
    global CHROMEDRIVER_PATH
    global CHROME_PATH
    global TMP_PATH

    # ì´ë¯¸ì§€ ì €ì¥ì„ ìœ„í•œ ë””ë ‰í† ë¦¬ ìƒì„±
    if not os.path.exists('./images'):
        os.makedirs('./images')
    
    # tmp/images ë””ë ‰í† ë¦¬ ìƒì„±
    tmp_images_path = f'{TMP_PATH}/images'
    if not os.path.exists(tmp_images_path):
        os.makedirs(tmp_images_path)
        print(f"ğŸ“ ì´ë¯¸ì§€ ì €ì¥ ë””ë ‰í† ë¦¬ ìƒì„±: {tmp_images_path}")

    # Airflow í™˜ê²½ì—ì„œëŠ” .env íŒŒì¼ì´ /usr/local/airflow/.envì— ë§ˆìš´íŠ¸ë¨
    load_dotenv(DIRECTORY_PATH + os.sep + '.env', override=True)
    

    if(os.name=='posix'): # ë¦¬ëˆ…ìŠ¤ í™˜ê²½
        CHROME_PATH = os.getenv("CHROME_PATH")
        CHROMEDRIVER_PATH = os.getenv("CHROMEDRIVER_PATH")
        TMP_PATH=os.getenv("TMP_PATH")
    else:
        CHROME_PATH = DIRECTORY_PATH + os.sep + os.getenv("CHROME_PATH")
        CHROMEDRIVER_PATH = DIRECTORY_PATH + os.sep + os.getenv("CHROMEDRIVER_PATH")

    print(DIRECTORY_PATH)
    print(CHROME_PATH)
    print(CHROMEDRIVER_PATH)
    
    os.environ["XDG_RUNTIME_DIR"] = "/tmp"
    # ì˜µì…˜ ì„¤ì •
    options = Options()
    options.add_argument("--headless=new")
    options.add_argument("--no-sandbox")
    options.add_argument("--disable-dev-shm-usage")
    options.add_argument("--remote-debugging-port=9222")
    options.add_argument("--user-data-dir=/tmp/chrome-user-data")
    options.add_argument("--data-path=/tmp/chrome-data")
    options.add_argument("--disk-cache-dir=/tmp/chrome-cache")
    options.add_argument("--disable-gpu")          # GPU ì—†ëŠ” í™˜ê²½ì—ì„œ ì•ˆì „ì¥ì¹˜
    options.add_argument("--disable-software-rasterizer")
    options.add_argument("--no-first-run")
    options.add_argument("--no-default-browser-check")
    options.binary_location = CHROME_PATH
    # ë“œë¼ì´ë²„ ê²½ë¡œ ì„¤ì • (chromedriver.exe ìœ„ì¹˜ì— ë§ê²Œ ìˆ˜ì •) 
    service = Service(executable_path=CHROMEDRIVER_PATH)
    driver = webdriver.Chrome(options = options, service=service)

def load_url_config():
    """naver_map_url.json íŒŒì¼ì„ ì½ì–´ì„œ URL ì„¤ì •ì„ ë¡œë“œí•©ë‹ˆë‹¤."""
    config_path = DIRECTORY_PATH + os.sep + 'naver_map_url.json'
    with open(config_path, 'r', encoding='utf-8') as f:
        return json.load(f)

def generate_urls(config):
    """JSON ì„¤ì •ì—ì„œ ëª¨ë“  URL ì¡°í•©ì„ ìƒì„±í•©ë‹ˆë‹¤."""
    urls = []
    url_template = config['url_template']
    locations = config['locations']
    queries = config['queries']
    
    for location in locations:
        for category, query_list in queries.items():
            for keyword in query_list:
                # URL ìƒì„±: https://map.naver.com/p/search/ê°•ë‚¨êµ¬ ê°•ì•„ì§€
                url = url_template.format(
                    location=location['name'],
                    keyword=keyword
                )
                urls.append({
                    'url': url,
                    'location': location['name'],
                    'category': category,
                    'query': f"{location['name']} {keyword}"
                })
    return urls

def download_image(image_url, place_name):
    """ì´ë¯¸ì§€ë¥¼ ë‹¤ìš´ë¡œë“œí•˜ê³  tmp/imagesì— ì €ì¥í•©ë‹ˆë‹¤."""
    try:
        # URLì—ì„œ ì´ë¯¸ì§€ ë‹¤ìš´ë¡œë“œ
        response = requests.get(image_url, timeout=10)
        if response.status_code == 200:
            # íŒŒì¼ëª… ìƒì„± (URL í•´ì‹œ + ì¥ì†Œëª…)
            url_hash = hashlib.md5(image_url.encode()).hexdigest()[:8]
            safe_place_name = "".join(c for c in place_name if c.isalnum() or c in (' ', '-', '_')).strip()[:30]
            filename = f"{safe_place_name}_{url_hash}.jpg"
            
            # ì´ë¯¸ì§€ ì €ì¥
            image_path = f'{TMP_PATH}/images/{filename}'
            with open(image_path, 'wb') as f:
                f.write(response.content)
            
            return filename
        else:
            print(f"  âš ï¸ ì´ë¯¸ì§€ ë‹¤ìš´ë¡œë“œ ì‹¤íŒ¨ (status: {response.status_code})")
            return None
    except Exception as e:
        print(f"  âš ï¸ ì´ë¯¸ì§€ ë‹¤ìš´ë¡œë“œ ì—ëŸ¬: {e}")
        return None

def export_ndjson(place_obj_list):
    """í¬ë¡¤ë§í•œ ì¥ì†Œ ë°ì´í„°ë¥¼ NDJSON íŒŒì¼ë¡œ ì €ì¥í•©ë‹ˆë‹¤."""
    with open(f'{TMP_PATH}/place_obj_list.ndjson', 'w', encoding='utf-8') as f:
        for place_obj in place_obj_list:
            f.write(json.dumps(place_obj, ensure_ascii=False) + '\n')


def crawl_single_page(url_info):
    """ë‹¨ì¼ URLì— ëŒ€í•´ í¬ë¡¤ë§ì„ ìˆ˜í–‰í•©ë‹ˆë‹¤."""
    url = url_info['url']
    location = url_info['location']
    category = url_info['category']
    query = url_info['query']
    
    print(f"\n{'='*80}")
    print(f"ğŸŒ í¬ë¡¤ë§ ì‹œì‘")
    print(f"   ìœ„ì¹˜: {location} | ì¹´í…Œê³ ë¦¬: {category} | ê²€ìƒ‰ì–´: {query}")
    print(f"   URL: {url}")
    print(f"{'='*80}")
    
    driver.switch_to.default_content()
    driver.get(url)
    time.sleep(3)
    
    place_list = []
    success_count = 0
    fail_count = 0
    
    #iframe ë³€ê²½
    driver.switch_to.default_content()
    driver.switch_to.frame("searchIframe")
    while True:
        driver.execute_script("window.scrollTo(0, document.body.scrollHeight);")
        time.sleep(2)

        li_elements = driver.find_elements(By.CSS_SELECTOR, '#_pcmap_list_scroll_container > ul > li')
        print(f"ğŸ“‹ ì°¾ì€ ì¥ì†Œ ë¦¬ìŠ¤íŠ¸ ê°œìˆ˜: {len(li_elements)}ê°œ")
        li_len = len(li_elements)
        print(str(li_len) + "ê°œì˜ li ì°¾ìŒ")
        for i in range(li_len):
            try:
                #iframe ë³€ê²½
                driver.switch_to.default_content()
                time.sleep(0.1)
                driver.switch_to.frame("searchIframe")
                time.sleep(0.1)
                li_elements = driver.find_elements(By.CSS_SELECTOR, '#_pcmap_list_scroll_container > ul > li')
                print(str(i)+"ë²ˆì§¸ li ì‹¤í–‰")
                li = li_elements[i]
                # ì¥ì†Œ í´ë¦­ ì‹œë„
                try:
                    click_element = li.find_element(By.CSS_SELECTOR, 'div.qbGlu > div.ouxiq > div.ApCpt > a')
                    click_element.click()
                except NoSuchElementException:
                    try:
                        click_element = li.find_element(By.CSS_SELECTOR, 'div.zzp3_ > div.TbelT > a')
                        click_element.click()
                    except NoSuchElementException:
                        print(f"  âš ï¸ í´ë¦­í•  ìš”ì†Œë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
                        continue
                
                # iframe ì „í™˜ ëŒ€ê¸°
                time.sleep(3)
                
                try:
                    # iframe ë³€ê²½
                    driver.switch_to.default_content()
                    time.sleep(0.1)
                    driver.switch_to.frame("entryIframe")
                    time.sleep(2)
                    
                    # ì œëª©ê³¼ ì¹´í…Œê³ ë¦¬ ì¶”ì¶œ
                    title_element = driver.find_element(By.CSS_SELECTOR, "#_title > div > span.GHAhO")
                    category_element = driver.find_element(By.CSS_SELECTOR, "#_title > div > span.lnJFt")
                    title = title_element.text
                    if("ì…ì–‘" in title or "ë¶„ì–‘" in title or "ë³´í˜¸" in title or "ìœ ê¸°" in title or "ëƒ„ìƒˆì œê±°" in title or "ê°€ì „" in title or "ì²­ì†Œ" in title):
                        continue
                    category = category_element.text
                    print(f"  ğŸ“ {title} - {category}")
                    
                    # ì£¼ì†Œ í† ê¸€ ë²„íŠ¼ í´ë¦­
                    toggle_button = driver.find_element(By.CSS_SELECTOR, "div.O8qbU.tQY7D > div > a")
                    toggle_button.click()
                    time.sleep(2)
                    
                    # ì£¼ì†Œ ì¶”ì¶œ
                    try:
                        address_div = driver.find_element(By.CSS_SELECTOR, "div.O8qbU.tQY7D > div > div.Y31Sf > div:nth-child(1)")
                        address = address_div.text.replace("ë„ë¡œëª…", "").strip()
                    except NoSuchElementException:
                        address = "ì£¼ì†Œ ì •ë³´ ì—†ìŒ"
                        
                except Exception as e:
                    print(f"  âš ï¸ ìƒì„¸ ì •ë³´ ì¶”ì¶œ ì‹¤íŒ¨: {e}")
                    # searchIframeìœ¼ë¡œ ëŒì•„ê°€ê¸°
                    driver.switch_to.default_content()
                    driver.switch_to.frame("searchIframe")
                    continue
                
                # ì´ë¯¸ì§€ ì°¾ê¸° ë° ë‹¤ìš´ë¡œë“œ
                image_filenames = []
                try:
                    # ì´ë¯¸ì§€ ìš”ì†Œ ì°¾ê¸° (ì—¬ëŸ¬ ì„ íƒì ì‹œë„)
                    img_elements = driver.find_elements(By.CSS_SELECTOR, 'div.uDR4i img')
                    for img in img_elements:
                        image_url = img.get_attribute('src')
                        if image_url:
                            print(f"ì´ë¯¸ì§€ ë°œê²¬: {image_url[:80]}...")
                            image_filename = download_image(image_url, title)
                            if image_filename:
                                image_filenames.append(image_filename)
                                print(f"ì´ë¯¸ì§€ ì €ì¥: {image_filename}")
                                
                except Exception as img_error:
                    print(f"â€»ì´ë¯¸ì§€ ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜: {img_error}")
                print(f"ì°¾ì€ ì´ë¯¸ì§€ ê°œìˆ˜: {len(image_filenames)}ê°œ")                            
                # searchIframeìœ¼ë¡œ ëŒì•„ê°€ê¸°
                driver.switch_to.default_content()
                time.sleep(0.1)
                driver.switch_to.frame("searchIframe")
                time.sleep(0.1)
                # ë°ì´í„° ì €ì¥
                place_obj = {
                    "placeName": title,
                    "category": category,
                    "address": address,
                    "location": location,
                    "searchCategory": category,
                    "searchQuery": query,
                    "imageFile": image_filenames
                }
                place_list.append(place_obj)
                success_count += 1
                print(f"âœ“ [{success_count}] {title}")
                
            except Exception as e:
                fail_count += 1
                print(f"âœ— í¬ë¡¤ë§ ì‹¤íŒ¨ (ì¥ì†Œ #{success_count + fail_count}): {e}")
                # searchIframeìœ¼ë¡œ ëŒì•„ê°€ê¸°
                try:
                    driver.switch_to.default_content()
                    driver.switch_to.frame("searchIframe")
                except:
                    pass
                continue
        #iframe ë³€ê²½
        driver.switch_to.default_content()
        time.sleep(0.1)
        driver.switch_to.frame("searchIframe")
        time.sleep(0.1)
        next_page_a = driver.find_element(By.CSS_SELECTOR, "#app-root > div > div.XUrfU > div.zRM9F > a:last-of-type")
        if next_page_a.get_attribute("aria-disabled") == "false":
            next_page_a.click()
            time.sleep(1)
        else:
            break
    print(f"âœ… ì™„ë£Œ - ì„±ê³µ: {success_count}ê°œ, ì‹¤íŒ¨: {fail_count}ê°œ")
    return place_list

def crawl(ti=None, **context):
    """ë„¤ì´ë²„ ì§€ë„ì—ì„œ ì¥ì†Œ ë°ì´í„°ë¥¼ í¬ë¡¤ë§í•©ë‹ˆë‹¤."""
    init()
    
    # URL ì„¤ì • ë¡œë“œ
    print("ğŸ“– URL ì„¤ì • íŒŒì¼ ë¡œë“œ ì¤‘...")
    config = load_url_config()
    url_list = generate_urls(config)
    print(f"âœ… ì´ {len(url_list)}ê°œì˜ URL ìƒì„± ì™„ë£Œ")
    print(f"   - ìœ„ì¹˜: {len(config['locations'])}ê°œ")
    print(f"   - ê²€ìƒ‰ì–´: {sum(len(queries) for queries in config['queries'].values())}ê°œ")
    
    # ëª¨ë“  URLì— ëŒ€í•´ í¬ë¡¤ë§ ìˆ˜í–‰
    all_place_obj_list = []
    total_success = 0
    total_fail = 0
    
    for idx, url_info in enumerate(url_list, 1):
        print(f"\n\nì§„í–‰ë¥ : [{idx}/{len(url_list)}]")
        try:
            place_list = crawl_single_page(url_info)
            all_place_obj_list.extend(place_list)
            total_success += len(place_list)
        except Exception as e:
            print(f"âŒ URL í¬ë¡¤ë§ ì‹¤íŒ¨: {e}")
            total_fail += 1
            continue
        export_ndjson(all_place_obj_list)
        print(f"ì¤‘ê°„ ì €ì¥ ì™„ë£Œ")
    
    # ë””ë²„ê¹…ìš© ìŠ¤í¬ë¦°ìƒ· ì €ì¥ (ë§ˆì§€ë§‰ í˜ì´ì§€)
    screenshot_path = f'{TMP_PATH}/debug_screenshot.png'
    driver.save_screenshot(screenshot_path)
    print(f"\nğŸ“¸ ë””ë²„ê·¸ ìŠ¤í¬ë¦°ìƒ· ì €ì¥: {screenshot_path}")
    
    # ë””ë²„ê¹…ìš© HTML ì €ì¥ (ë§ˆì§€ë§‰ í˜ì´ì§€)
    html_path = f'{TMP_PATH}/debug_page.html'
    with open(html_path, 'w', encoding='utf-8') as f:
        f.write(driver.page_source)
    print(f"ğŸ“„ ë””ë²„ê·¸ HTML ì €ì¥: {html_path}")
    
    # ë°±ì—…ìš©ìœ¼ë¡œ NDJSON ì €ì¥
    export_ndjson(all_place_obj_list)
    
    print(f"\n{'='*80}")
    print(f"=== ì „ì²´ í¬ë¡¤ë§ ì™„ë£Œ ===")
    print(f"í¬ë¡¤ë§í•œ URL: {len(url_list)}ê°œ")
    print(f"ìˆ˜ì§‘ëœ ì¥ì†Œ: {len(all_place_obj_list)}ê°œ")
    print(f"ì„±ê³µ: {total_success}ê°œ")
    print(f"ì‹¤íŒ¨: {total_fail}ê°œ")
    print(f"{'='*80}")
    
    # ì¢…ë£Œ
    driver.quit()
    
    # ì¥ì†Œ ë¦¬ìŠ¤íŠ¸ë¥¼ XComìœ¼ë¡œ ë°˜í™˜ (Dynamic Task Mappingì—ì„œ ì‚¬ìš©)
    return all_place_obj_list


